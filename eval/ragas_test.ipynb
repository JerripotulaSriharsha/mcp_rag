{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b08580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import faiss\n",
    "import openai\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2accfce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"Paris is the capital and most populous city of France. The city is famed for the Eiffel Tower.\",\n",
    "    \"Jane Austen was an English novelist best known for 'Pride and Prejudice' and 'Sense and Sensibility'.\",\n",
    "    \"The Great Wall of China is a series of fortifications built to protect the ancient Chinese states.\",\n",
    "    \"Mount Everest, part of the Himalayas, is Earth’s highest mountain above sea level.\",\n",
    "    \"Mike loves the color pink more than any other color.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df0fbf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "def get_embedding(text):\n",
    "    response = client.embeddings.create(model=\"text-embedding-ada-002\", input=text)\n",
    "    return response.data[0].embedding\n",
    "embeddings = np.array([get_embedding(d) for d in docs]).astype('float32')\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "faiss.normalize_L2(embeddings)\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b26d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, k):\n",
    "    query_embedding = np.array([get_embedding(query)]).astype(\"float32\")\n",
    "    \n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    _, idx = index.search(query_embedding, k)\n",
    "    \n",
    "    return [docs[i] for i in idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4459237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question, contexts):\n",
    "    prompt = (\n",
    "        \"Answer the user question **only** with facts found in the context.\\n\\n\"\n",
    "        \"Context:\\n\"\n",
    "        + \"\\n\".join(f\"- {c}\" for c in contexts)\n",
    "        + f\"\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b97d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "questions = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Who wrote Pride and Prejudice?\",\n",
    "    \"Where is Mount Everest located?\",\n",
    "    \"What is Mike's favorite color?\"\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    \"Paris\",\n",
    "    \"Jane Austen\",\n",
    "    \"the Himalayas\",\n",
    "    \"Pink\"\n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for question, ground_truth in zip(questions, ground_truths):\n",
    "    context = retrieve(question, k=2)\n",
    "    answer = generate_answer(question, context)\n",
    "    rows.append(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"contexts\": context,\n",
    "            \"answer\": answer,\n",
    "            \"reference\": ground_truth,\n",
    "        }\n",
    "    )\n",
    "\n",
    "evaluation_dataset = Dataset.from_list(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cab048cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'contexts', 'answer', 'reference'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2624f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriha\\AppData\\Local\\Temp\\ipykernel_39044\\1053983174.py:2: DeprecationWarning: Importing answer_correctness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import answer_correctness\n",
      "  from ragas.metrics import (\n",
      "C:\\Users\\sriha\\AppData\\Local\\Temp\\ipykernel_39044\\1053983174.py:2: DeprecationWarning: Importing answer_relevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import answer_relevancy\n",
      "  from ragas.metrics import (\n",
      "C:\\Users\\sriha\\AppData\\Local\\Temp\\ipykernel_39044\\1053983174.py:2: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
      "  from ragas.metrics import (\n",
      "C:\\Users\\sriha\\AppData\\Local\\Temp\\ipykernel_39044\\1053983174.py:2: DeprecationWarning: Importing context_precision from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_precision\n",
      "  from ragas.metrics import (\n",
      "C:\\Users\\sriha\\AppData\\Local\\Temp\\ipykernel_39044\\1053983174.py:2: DeprecationWarning: Importing context_recall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_recall\n",
      "  from ragas.metrics import (\n",
      "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]Exception raised in Job[0]: TypeError(Cannot use aembed_text() with a synchronous client. Use embed_text() instead.)\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Exception raised in Job[1]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "Exception raised in Job[5]: TypeError(Cannot use aembed_text() with a synchronous client. Use embed_text() instead.)\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Exception raised in Job[6]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "Exception raised in Job[10]: TypeError(Cannot use aembed_text() with a synchronous client. Use embed_text() instead.)\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Exception raised in Job[11]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "Exception raised in Job[15]: TypeError(Cannot use aembed_text() with a synchronous client. Use embed_text() instead.)\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Exception raised in Job[16]: AttributeError('OpenAIEmbeddings' object has no attribute 'embed_query')\n",
      "Evaluating: 100%|██████████| 20/20 [01:00<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'question': 'What is the capital of France?', 'contexts': ['Paris is the capital and most populous city of France. The city is famed for the Eiffel Tower.', 'The Great Wall of China is a series of fortifications built to protect the ancient Chinese states.'], 'answer': 'The capital of France is Paris.', 'reference': 'Paris'}, {'question': 'Who wrote Pride and Prejudice?', 'contexts': [\"Jane Austen was an English novelist best known for 'Pride and Prejudice' and 'Sense and Sensibility'.\", 'Paris is the capital and most populous city of France. The city is famed for the Eiffel Tower.'], 'answer': \"Jane Austen wrote 'Pride and Prejudice'.\", 'reference': 'Jane Austen'}, {'question': 'Where is Mount Everest located?', 'contexts': ['Mount Everest, part of the Himalayas, is Earth’s highest mountain above sea level.', 'The Great Wall of China is a series of fortifications built to protect the ancient Chinese states.'], 'answer': 'Mount Everest is located in the Himalayas.', 'reference': 'the Himalayas'}, {'question': \"What is Mike's favorite color?\", 'contexts': ['Mike loves the color pink more than any other color.', 'Paris is the capital and most populous city of France. The city is famed for the Eiffel Tower.'], 'answer': \"Mike's favorite color is pink.\", 'reference': 'Pink'}]\n",
      "{'answer_correctness': nan, 'answer_relevancy': nan, 'faithfulness': 1.0000, 'context_precision': 1.0000, 'context_recall': 1.0000}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_correctness,\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "scores = evaluate(\n",
    "    evaluation_dataset,\n",
    "    metrics=[\n",
    "        answer_correctness,\n",
    "        answer_relevancy,\n",
    "        faithfulness,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(rows)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276fa92e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
