{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caa37f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41803732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "PERSISTENT_DIR = \"./chroma_db\"\n",
    "COLLECTION_NAME = \"rag_mcp\"\n",
    "\n",
    "def get_collection():\n",
    "    client = chromadb.PersistentClient(path=PERSISTENT_DIR)\n",
    "\n",
    "    embedding_fn = OpenAIEmbeddingFunction(\n",
    "        api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        model_name=\"text-embedding-ada-002\",  # works; if deprecated, use text-embedding-3-small\n",
    "    )\n",
    "\n",
    "    collection = client.get_or_create_collection(\n",
    "        name=COLLECTION_NAME,\n",
    "        embedding_function=embedding_fn,\n",
    "    )\n",
    "    return client, collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "180b8c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "nest_asyncio.apply()  # REQUIRED for Jupyter on Windows\n",
    "\n",
    "DATA_DIR = r\"D:\\Narwal\\mcp_rag\\data\"\n",
    "LLAMA_CLOUD_API_KEY = os.environ[\"LLAMA_CLOUD_API_KEY\"]\n",
    "\n",
    "def ingest_data_dir():\n",
    "    client, _ = get_collection()\n",
    "\n",
    "    # wipe and re-create collection (dev-safe)\n",
    "    try:\n",
    "        client.delete_collection(name=COLLECTION_NAME)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    client, collection = get_collection()\n",
    "\n",
    "    parser = LlamaParse(\n",
    "        api_key=LLAMA_CLOUD_API_KEY,\n",
    "        result_type=\"text\",\n",
    "    )\n",
    "\n",
    "    file_extractor = {\".pdf\": parser}\n",
    "\n",
    "    documents = SimpleDirectoryReader(\n",
    "        DATA_DIR,\n",
    "        file_extractor=file_extractor,\n",
    "    ).load_data()\n",
    "\n",
    "    for doc in documents:\n",
    "        collection.add(\n",
    "            documents=[doc.text],\n",
    "            metadatas=[doc.metadata],\n",
    "            ids=[doc.doc_id],\n",
    "        )\n",
    "\n",
    "    print(f\"Ingested {collection.count()} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "312633a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 02:15:07,110 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 617263f5-21c4-4ecf-9a41-8c6842f4964b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 02:15:08,370 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/617263f5-21c4-4ecf-9a41-8c6842f4964b \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:15:10,654 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/617263f5-21c4-4ecf-9a41-8c6842f4964b \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:15:13,873 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/617263f5-21c4-4ecf-9a41-8c6842f4964b \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:15:18,191 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/617263f5-21c4-4ecf-9a41-8c6842f4964b \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:15:45,022 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/617263f5-21c4-4ecf-9a41-8c6842f4964b \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:15:45,431 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/617263f5-21c4-4ecf-9a41-8c6842f4964b/result/text \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while parsing the file '<bytes/buffer>': Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 02:15:59,264 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 02:16:00,586 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:03,146 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:06,423 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:10,702 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:16,663 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:22,352 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:29,155 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:34,475 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:34,801 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f/result/text \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:37,293 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ingest_data_dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3117a30a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
