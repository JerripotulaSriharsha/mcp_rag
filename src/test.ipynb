{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caa37f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41803732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "PERSISTENT_DIR = \"./chroma_db\"\n",
    "COLLECTION_NAME = \"rag_mcp\"\n",
    "\n",
    "def get_collection():\n",
    "    client = chromadb.PersistentClient(path=PERSISTENT_DIR)\n",
    "\n",
    "    embedding_fn = OpenAIEmbeddingFunction(\n",
    "        api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        model_name=\"text-embedding-ada-002\",  # works; if deprecated, use text-embedding-3-small\n",
    "    )\n",
    "\n",
    "    collection = client.get_or_create_collection(\n",
    "        name=COLLECTION_NAME,\n",
    "        embedding_function=embedding_fn,\n",
    "    )\n",
    "    return client, collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "180b8c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_parse import LlamaParse\n",
    "\n",
    "nest_asyncio.apply()  # REQUIRED for Jupyter on Windows\n",
    "\n",
    "DATA_DIR = r\"D:\\Narwal\\mcp_rag\\data\"\n",
    "LLAMA_CLOUD_API_KEY = os.environ[\"LLAMA_CLOUD_API_KEY\"]\n",
    "\n",
    "def ingest_data_dir():\n",
    "    client, _ = get_collection()\n",
    "\n",
    "    # wipe and re-create collection (dev-safe)\n",
    "    try:\n",
    "        client.delete_collection(name=COLLECTION_NAME)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    client, collection = get_collection()\n",
    "\n",
    "    parser = LlamaParse(\n",
    "        api_key=LLAMA_CLOUD_API_KEY,\n",
    "        result_type=\"text\",\n",
    "    )\n",
    "\n",
    "    file_extractor = {\".pdf\": parser}\n",
    "\n",
    "    documents = SimpleDirectoryReader(\n",
    "        DATA_DIR,\n",
    "        file_extractor=file_extractor,\n",
    "    ).load_data()\n",
    "\n",
    "    for doc in documents:\n",
    "        collection.add(\n",
    "            documents=[doc.text],\n",
    "            metadatas=[doc.metadata],\n",
    "            ids=[doc.doc_id],\n",
    "        )\n",
    "\n",
    "    print(f\"Ingested {collection.count()} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "312633a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 02:15:07,110 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 617263f5-21c4-4ecf-9a41-8c6842f4964b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 02:15:08,370 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/617263f5-21c4-4ecf-9a41-8c6842f4964b \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:15:10,654 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/617263f5-21c4-4ecf-9a41-8c6842f4964b \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:15:13,873 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/617263f5-21c4-4ecf-9a41-8c6842f4964b \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:15:18,191 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/617263f5-21c4-4ecf-9a41-8c6842f4964b \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:15:45,022 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/617263f5-21c4-4ecf-9a41-8c6842f4964b \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:15:45,431 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/617263f5-21c4-4ecf-9a41-8c6842f4964b/result/text \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while parsing the file '<bytes/buffer>': Event loop is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 02:15:59,264 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-22 02:16:00,586 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:03,146 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:06,423 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:10,702 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:16,663 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:22,352 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:29,155 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:34,475 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:34,801 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2b57ffe1-e8a1-4b78-aa60-5a6bc960cc3f/result/text \"HTTP/1.1 200 OK\"\n",
      "2025-12-22 02:16:37,293 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ingest_data_dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3117a30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScoredPoint(id='9f073b3b-9107-4aa9-923e-2604298c0395', version=11, score=0.81821674, payload={'text': '-\\nsidering both geometry and all physical attributes.                                In to-\\ntal, we collect 1,568 valid scores from 14 volunteers and\\nnormalize the scores. The results show that the outputs of\\nPhysX-Anything align much better with human preferences\\nthan those of other methods, confirming its robust gener-\\native performance in both geometry and physical proper-\\n\\n                                                                                                     6\\n', 'metadata': {'file_path': 'D:\\\\Narwal\\\\mcp_rag\\\\data\\\\paper1.pdf', 'file_name': 'paper1.pdf', 'file_type': 'application/pdf', 'file_size': 4994615, 'creation_date': '2025-12-22', 'last_modified_date': '2025-12-22'}, 'chunk_index': 1, 'source_doc': 'dca54582-14cc-44a2-acaa-a22cbd7cdeb9'}, vector=None, shard_key=None, order_value=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ---- config ----\n",
    "COLLECTION_NAME = \"rag_mcp\"\n",
    "\n",
    "# ---- clients ----\n",
    "openai_client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "qdrant = QdrantClient(\n",
    "    url=os.environ[\"QDRANT_URL\"],\n",
    "    api_key=os.environ[\"QDRANT_API_KEY\"],\n",
    ")\n",
    "\n",
    "# ---- make a query embedding ----\n",
    "query_text = \"physics simulation\"\n",
    "\n",
    "embedding = openai_client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=query_text,\n",
    ").data[0].embedding\n",
    "\n",
    "# ---- query ONE result ----\n",
    "resp = qdrant.query_points(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    query=embedding,\n",
    "    limit=1,\n",
    "    with_payload=True,\n",
    ")\n",
    "\n",
    "# ---- print EVERYTHING ----\n",
    "point = resp.points[0]\n",
    "\n",
    "point \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e0784a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "VOYAGE_API_KEY = os.environ[\"VOYAGE_API_KEY\"]\n",
    "url = \"https://api.voyageai.com/v1/rerank\"\n",
    "\n",
    "def rerank(query: str, chunks: list[str], top_k: int = 5):\n",
    "    payload = {\n",
    "        \"model\": \"rerank-2.5\",   # or \"rerank-2.5\"\n",
    "        \"query\": query,\n",
    "        \"documents\": chunks,\n",
    "        \"top_k\": top_k,\n",
    "    }\n",
    "    headers = {\"Authorization\": f\"Bearer {VOYAGE_API_KEY}\"}\n",
    "    r = requests.post(url, json=payload, headers=headers)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "query = \"What is Model Context Protocol?\"\n",
    "\n",
    "chunks = [\n",
    "    \"Model Context Protocol (MCP) is a standard that allows large language models to call tools using a structured interface.\",\n",
    "    \"FastAPI is a modern Python web framework used to build APIs quickly and efficiently.\",\n",
    "    \"MCP enables LLMs to interact with external systems through JSON-RPC style messages.\",\n",
    "    \"Qdrant is a vector database designed for similarity search and retrieval.\",\n",
    "    \"The protocol defines how models expose tools and how clients invoke them.\"\n",
    "]\n",
    "result = rerank(query, chunks, top_k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7067c073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'list',\n",
       " 'data': [{'relevance_score': 0.890625, 'index': 0},\n",
       "  {'relevance_score': 0.7109375, 'index': 4},\n",
       "  {'relevance_score': 0.6328125, 'index': 2}],\n",
       " 'model': 'rerank-2.5',\n",
       " 'usage': {'total_tokens': 93}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98568fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
